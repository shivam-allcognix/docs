---
title: 'Getting Started with Integration'
description: 'Step-by-step guide to integrating Omni Model Market into your applications'
icon: 'code'
---

Step-by-step guide to integrating Omni Model Market into your applications

## Integration Overview

Omni Model Market provides APIs that make it easy to integrate models and generation tools into your applications. This guide will walk you through the complete integration process.

## Prerequisites

Before you start integrating Omni Model Market Studio, ensure you have:

* **API Key**: Create your API key from the [website](https://modelmarket.allcognix.com)
* **HTTP Client**: Any HTTP client library (requests, fetch, axios, etc.)
* **Base URL**: `https://modelmarket.allcognix.com`

## Steps for integration

<Steps>
  <Step title="Set Up Authentication">
    Login to website, configure your API key and user identification.
  </Step>
  <Step title="Model Selection">
    Visit the explore page of website. Choose from text, vision, audio, video, or code-generation models for your application.
  </Step>

  <Step title="Call the API">
    Prepare the payload and hit the endpoint to get the expected result in formatted manner.
  </Step>

  <Step title="Handle Responses">
    Process and use the results to integrate in your application.
  </Step>

  <Step title="Monitor and Optimize">
    Track usage, costs, and performance from the dashboard.
  </Step>
</Steps>

## Step 1: Set Up Authentication

### API Key Configuration

Store your API key securely in environment variables:

```python  theme={null}
# Python
import os
from dotenv import load_dotenv

load_dotenv()
API_KEY = os.getenv('MODEL_MARKET_API_KEY')
URL = os.getenv('MODEL_MARKET_URL') or "https://modelmarket.allcognix.com/v1/mmk-generate"
```

### HTTP Client Setup

```python  theme={null}
# Python with requests
import requests

headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}
```

## Step 2: Model Selection

You can explore the full list of model on the explore page of the website: [modelmarket.allcognix.com/dashboard/explore](https://modelmarket.allcognix.com/explore):

## Step 3: Call the API

1. You can run any model on Omni Model Market from your Python code. Here’s an example that runs minimax/speech-02-hd to generate an audio from the text:

```python  theme={null}
def generate():
    payload = {
        "model": "minimax/speech-02-hd",
        "text": "Voice cloning technology that offers voice synthesis, emotional expression, and multilingual capabilities."
    }
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    response = requests.post(URL, json=payload, headers=headers, timeout=120)
    output =
    if response.status_code == 200:
        result = response.json()
        return result
    else:
        raise Exception(f"Failed to create collection: {response.json()['detail']}")
```
2. For streaming method supporting models, you can call like this:
```python  theme={null}
def stream():
    url = BASE_URL + ENDPOINT
    payload = { 
                "model": "openai/gpt-5",
                "prompt": "Tell me the story of the green goblin in 50 words.",
                "messages": [],
                "verbosity": "medium",
                "image_input": [],
                "reasoning_effort": "minimal"
                }
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    print("Streaming response...\n")
    with requests.post(url, json=payload, headers=headers, stream=True) as r:
        for chunk in r.iter_lines():
            if chunk:
                print(chunk.decode(), end="", flush=True)
```  

## Step 4: Handling output

Process and use response results effectively. A typical successful response will look like this:

```python  theme={null}
{
  "output": {
    "type": "audio",
    "urls": [
      "https://replicate.delivery/xezq/TugNv7N1iZL7AVfEVm2OrUoX8fuOMfwTgi5spd..."
    ]
  },
  "cost": 0.0106,
  "service": "replicate",
  "status": "success",
  "created_at": "2025-11-24T11:13:16.948584Z",
  "generated_in": "2.5s"
}
```
Some models generate files as output, such as images or audio. These are returned in url fields, which you can easily save or process

```bash
import requests
file_url = result.get("output")["urls"][0]
with open("test.mp3", "wb") as f:
  f.write(file_url.content)
  print("Saved: test.mp3")
```
But some models can generate output in streaming fashion, so you need to process that output as per your use case:
```bash
Streaming response...

The Green Goblin, Norman Osborn, brilliant industrialist corrupted by a risky serum, gains strength and madness. Donning a goblin mask, glider, and pumpkin bombs, he becomes Spider-Man’s nemesis. He discovers Peter Parker’s identity, kills Gwen Stacy, dies, returns repeatedly, embodying obsession, tragedy, and the peril of unchecked ambition.<<END>>{"type": "final", "provider_output": {"cost": 0.0005, "service": "replicate", "created_at": "2025-12-16T05:24:11.476542Z", "generated_in": "2.62s"}}
```
## Step 5: Monitor and Optimize
To keep your usage efficient and cost-effective, follow these best practices:

- Track Cost in Each Response: Every call returns a cost field. Store this in your logs or database to monitor usage patterns.
- Choose the Right Model: Some models are cheaper/faster alternatives. You can browse them on: [https://modelmarket.allcognix.com/explore](https://modelmarket.allcognix.com/explore)
- Handle Errors Gracefully: A few typical error reasons can be Invalid/missing API key, Timeout, Unsupported model parameters, Provider-side failure.

## Complete Integration Example

Here's a complete example that demonstrates all integration steps:
a) For generation:
```python  theme={null}
import os
import requests
from dotenv import load_dotenv
# Load environment variables

load_dotenv()
API_KEY = os.getenv("MODEL_MARKET_API_KEY")
URL = "https://modelmarket.allcognix.com/v1/mmk-generate" # For generate
# URL = "https://modelmarket.allcognix.com/v1/mmk-generate" # For stream

headers = {
"Authorization": f"Bearer {API_KEY}",
"Content-Type": "application/json"
}

def generate_audio():
    payload = {"model": "minimax/speech-02-hd", "text": "Voice cloning technology that offers high-quality synthesis."}
    response = requests.post(URL, json=payload, headers=headers, timeout=120)
    response.raise_for_status()
    data = response.json()
    print("Status:", data["status"])
    print("Cost:", data["cost"])
    print("Provider:", data["service"])
    # Handle output (audio file)
    if data["output"]["type"] == "audio":
        audio_url = data["output"]["urls"][0]
        download_file(audio_url, "generated_audio.wav")
    return data

def download_file(url, filename):
  file_data = requests.get(url)
  with open(filename, "wb") as f:
    f.write(file_data.content)
    print(f"Saved file as {filename}")

if name == "main":
result = generate_audio()
print("Full result:", result)
```

b) For streaming models:
```python  theme={null}
import os, json
import requests
from dotenv import load_dotenv
# Load environment variables
load_dotenv()
API_KEY = os.getenv("MODEL_MARKET_API_KEY")
URL = "https://modelmarket.allcognix.com/v1/mmk-chat" # For chat

def main():
    url = BASE_URL + ENDPOINT
    payload = { 
                "model": "openai/gpt-5",
                "prompt": "Tell me the story of the green goblin in 50 words.",
                "messages": [],
                "verbosity": "medium",
                "image_input": [],
                "reasoning_effort": "minimal"
                }
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    print("Streaming response...\n")
    with requests.post(url, json=payload, headers=headers, stream=True) as r:
        for chunk in r.iter_lines():
            if chunk:
                print(chunk.decode(), end="", flush=True)
```

## Next Steps

<Card title="Web Guide" icon="code" href="/essential/web-guide">
  See a complete guide to experiment the model playground.
</Card>

<Card title="Examples" icon="robot" href="/essential/examples">
  Some more examples to make you clear with the model playground.
</Card>